# Story 1.5: Basic CLI Download Command

**Story ID**: 1.5  
**Epic**: Epic 1 - Foundation & Streaming Pipeline  
**Status**: Draft  
**Priority**: High  
**Estimated Effort**: 1 day  
**Created**: 2025-08-07  

## User Story

**As a** user,  
**I want** to download a single day of SPX options data with a simple command,  
**So that** I can start acquiring data immediately.

## Story Context

**Existing System Integration:**
- Integrates with: DataPipeline service, BulkGreeksProcessor, CsvDataWriter
- Technology: Effect-TS, Bun CLI, TypeScript
- Follows pattern: Effect CLI command patterns
- Touch points: DataPipeline.process, BulkGreeksProcessor.streamBulkGreeks

## Acceptance Criteria

**Functional Requirements:**
1. Implement `download --date YYYY-MM-DD` command using Effect CLI
2. Display progress indicator showing expirations processed
3. Create trade date directory structure: `./data/YYYYMMDD/`
4. Save each expiration to its own file: `./data/YYYYMMDD/spxw_exp_YYYYMMDD.csv`
5. Handle invalid date formats with clear error messages
6. Support `--help` option displaying usage instructions

**Integration Requirements:**
7. Existing DataPipeline service continues to work unchanged
8. New functionality follows existing Effect CLI patterns
9. Integration with BulkGreeksProcessor maintains current behavior

**Quality Requirements:**
10. Change is covered by appropriate tests
11. Documentation is updated (README with CLI usage)
12. No regression in existing functionality verified

## Technical Implementation Tasks

### TDD Workflow Order:
1. Define CLI command interface and types
2. Create test suite for download command
3. Write tests for each functional requirement
4. Implement Live layer to make tests pass

### Task 1: CLI Command Definition (AC: 1, 6)
- [ ] Create `src/cli/commands/download.ts` using `@effect/cli`
- [ ] Import `Command` and `Options` from `@effect/cli`
- [ ] Define date option using `Options.text('date')` with description
- [ ] Create DownloadError tagged error type for command-specific errors
- [ ] Add date validation using Effect Schema or custom validator

### Task 2: Test Suite Creation (TDD Step 2)
- [ ] Create `test/cli/download.test.ts` following project test structure
- [ ] Setup test fixtures with mock services using TestLive layers
- [ ] Create test cases for valid date inputs
- [ ] Create test cases for invalid date formats
- [ ] Create test cases for progress tracking

### Task 3: Core Download Implementation (AC: 2, 3, 4)
- [ ] Implement download command logic in `src/cli/commands/download.ts`
- [ ] Parse and validate date argument using Effect Schema or custom validator
- [ ] Create output directory structure `./data/YYYYMMDD/` using `Bun.$\`mkdir -p\``
- [ ] Configure DataPipeline with appropriate output paths
- [ ] Wire up BulkGreeksProcessor.streamBulkGreeks with DataPipeline.process
- [ ] Note: CsvDataWriter already handles file creation with Bun APIs - leverage existing implementation

### Task 4: Progress Indicator Implementation (AC: 2)
- [ ] Create ProgressDisplay service interface
- [ ] Implement console-based progress display
- [ ] Integrate with MetricsCollector for real-time updates
- [ ] Display expirations processed count and current expiration
- [ ] Show throughput metrics (records/sec, completion %)

### Task 5: Error Handling Implementation (AC: 5)
- [ ] Implement date validation with descriptive error messages
- [ ] Add Effect.catchTag for API-specific errors
- [ ] Add file system error handling with recovery suggestions
- [ ] Implement graceful shutdown on SIGINT (Ctrl+C)
- [ ] Ensure resource cleanup with Effect.ensuring

### Task 6: CLI Entry Point (AC: 1)
- [ ] Create `src/cli/commands/download.ts` following the health command pattern
- [ ] Use `Command.make` from `@effect/cli` to define download command
- [ ] Add date option using `Options.text` with validation
- [ ] Wire up command in `src/cli/main.ts` with other subcommands
- [ ] Ensure BunContext.layer is included in MainLive layers

### Task 7: Integration Tests (AC: 10)
- [ ] Create `test/integration/download.integration.test.ts` if needed
- [ ] Use TestLive layers for mocked services
- [ ] Verify correct directory structure creation
- [ ] Verify file naming convention compliance
- [ ] Test interrupt handling and cleanup
- [ ] Verify metrics are written correctly using test fixtures

### Task 8: Documentation Updates (AC: 11)
- [ ] Update README with CLI usage examples
- [ ] Document all command options and parameters
- [ ] Add examples for common use cases
- [ ] Include troubleshooting guide for common errors
- [ ] Document output file structure and format

## Dev Notes

### Relevant Source Tree
Based on completed Story 1.4, the following components are available:
- `src/services/DataPipeline.ts` - Main pipeline orchestration service
- `src/services/BulkGreeksProcessor.ts` - Streaming data processor
- `src/layers/CsvDataWriter.ts` - CSV file writer implementation
- `src/services/MetricsCollector.ts` - Progress tracking

### Integration Points from Story 1.4
The DataPipeline service accepts a configuration with:
- `outputDir`: Base directory for writing files
- `chunkSize`: Number of records per chunk (default: 1000)
- `format`: Output format ('csv' | 'parquet')

The BulkGreeksProcessor.streamBulkGreeks returns a Stream<ExpirationResult> that can be piped directly to DataPipeline.process.

### Effect CLI Pattern (Bun Runtime)
Follow the project's established patterns for CLI implementation with Bun:
- Use `@effect/cli` for command definition and argument parsing
- Use `@effect/platform-bun` with `BunContext` and `BunRuntime`
- Use `Command.make` from `@effect/cli` to define commands with options
- Use `Effect.gen` with `yield* _()` for effect composition and sequential operations
- Use `Effect.pipe` for functional composition
- Use `Effect.provide` to supply required dependencies (layers)
- Handle errors with `Effect.catchAll` and `Effect.catchTag`
- Use `Effect.ensuring` for resource cleanup on interruption

Example structure following project patterns:
```typescript
import { Command } from '@effect/cli'
import { BunContext } from '@effect/platform-bun'
import { Effect } from 'effect'

export const download = Command.make('download', {
  date: Options.text('date').pipe(
    Options.withDescription('Date in YYYY-MM-DD format')
  )
}, ({ date }) =>
  Effect.gen(function* (_) {
    // Command logic using yield* _()
    const result = yield* _(someEffect)
    return result
  }).pipe(
    Effect.catchAll((error) =>
      Effect.gen(function* (_) {
        yield* _(Effect.log(`Error: ${error}`))
        return Effect.fail(error)
      })
    )
  )
).pipe(Command.withDescription('Download SPX options data for a specific date'))

// In main CLI file:
const MainLive = Layer.mergeAll(/* required layers */, BunContext.layer)

// Using BunRuntime for main entry point
BunRuntime.runMain(program)
```

### File Naming Convention
Each expiration file should be named: `spxw_exp_YYYYMMDD.csv` where YYYYMMDD is the expiration date (not trade date).

### Filesystem Operations with Bun
Follow the project's established patterns for filesystem operations:
- Use `Bun.write()` for writing files (as seen in JsonMetricsWriter)
- Use `Bun.file()` for file operations and creating writers (as seen in CsvDataWriter)
- Use `Bun.$` template literals for shell commands like `mkdir -p` (faster than Node.js fs)
- Example: `await Bun.$\`mkdir -p ${dirPath}\`.quiet()` for directory creation
- The CsvDataWriter already handles file operations using Bun's native APIs, so integrate with that service

## Testing

### Testing Standards from Architecture
- Test file location: `test/cli/download.test.ts` (following project structure)
- Test framework: Bun test (`bun:test`) with Effect-TS utilities
- Follow existing test patterns from `test/health.test.ts` and `test/services/DataPipeline.test.ts`
- Mock external services using TestLive layers from `@/layers/TestLive`
- Use test fixtures and mock services for isolation
- Verify file outputs using temporary directories

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-08-07 | 1.0 | Initial story creation | Sarah (PO) |

## Definition of Done

- [ ] Functional requirements met (CLI command works with date parameter)
- [ ] Integration requirements verified (existing services work unchanged)
- [ ] Existing functionality regression tested
- [ ] Code follows existing Effect-TS patterns and standards
- [ ] Tests pass (existing and new)
- [ ] README documentation updated with usage examples

## Risk and Compatibility Check

**Minimal Risk Assessment:**
- **Primary Risk:** File system permissions or disk space issues
- **Mitigation:** Check write permissions and available space before processing
- **Rollback:** Command is additive only, no existing functionality modified

**Compatibility Verification:**
- [x] No breaking changes to existing APIs
- [x] Database changes (if any) are additive only (N/A - file system only)
- [x] UI changes follow existing design patterns (N/A - CLI only)
- [x] Performance impact is negligible (uses existing streaming pipeline)

## Validation Checklist

**Scope Validation:**
- [x] Story can be completed in one development session (1 day estimate)
- [x] Integration approach is straightforward (uses existing services)
- [x] Follows existing patterns exactly (Effect CLI patterns)
- [x] No design or architecture work required

**Clarity Check:**
- [x] Story requirements are unambiguous
- [x] Integration points are clearly specified
- [x] Success criteria are testable
- [x] Rollback approach is simple (remove new CLI command file)

---
## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled*

### Debug Log References
*To be filled*

### Completion Notes List
*To be filled*

### File List
*To be filled*

## QA Results
*This section will be populated by the QA agent after implementation*